var te=Object.defineProperty;var re=(t,e,r)=>e in t?te(t,e,{enumerable:!0,configurable:!0,writable:!0,value:r}):t[e]=r;var b=(t,e,r)=>re(t,typeof e!="symbol"?e+"":e,r);import{g as ne}from"./time-Bu1cAEOJ.js";import{a as ae}from"./text-C_W9g4td.js";function se(t,e,r){return`${`[${new Date().toISOString()}] [${t.toUpperCase()}]`} ${e}`}function v(t,e,...r){const n=se(t,e);switch(t){case"error":console.error(n,...r);break;case"warn":console.warn(n,...r);break;case"info":case"debug":default:console.log(n,...r);break}}const a={info:(t,...e)=>v("info",t,...e),warn:(t,...e)=>v("warn",t,...e),error:(t,...e)=>v("error",t,...e),debug:(t,...e)=>v("debug",t,...e)};async function ie(t){const r=new TextEncoder().encode(t),n=await crypto.subtle.digest("SHA-256",r);return Array.from(new Uint8Array(n)).map(i=>i.toString(16).padStart(2,"0")).join("").slice(0,16)}const L=(t,e)=>e.some(r=>t instanceof r);let N,F;function oe(){return N||(N=[IDBDatabase,IDBObjectStore,IDBIndex,IDBCursor,IDBTransaction])}function ce(){return F||(F=[IDBCursor.prototype.advance,IDBCursor.prototype.continue,IDBCursor.prototype.continuePrimaryKey])}const $=new WeakMap,M=new WeakMap,I=new WeakMap;function le(t){const e=new Promise((r,n)=>{const s=()=>{t.removeEventListener("success",o),t.removeEventListener("error",i)},o=()=>{r(w(t.result)),s()},i=()=>{n(t.error),s()};t.addEventListener("success",o),t.addEventListener("error",i)});return I.set(e,t),e}function ue(t){if($.has(t))return;const e=new Promise((r,n)=>{const s=()=>{t.removeEventListener("complete",o),t.removeEventListener("error",i),t.removeEventListener("abort",i)},o=()=>{r(),s()},i=()=>{n(t.error||new DOMException("AbortError","AbortError")),s()};t.addEventListener("complete",o),t.addEventListener("error",i),t.addEventListener("abort",i)});$.set(t,e)}let B={get(t,e,r){if(t instanceof IDBTransaction){if(e==="done")return $.get(t);if(e==="store")return r.objectStoreNames[1]?void 0:r.objectStore(r.objectStoreNames[0])}return w(t[e])},set(t,e,r){return t[e]=r,!0},has(t,e){return t instanceof IDBTransaction&&(e==="done"||e==="store")?!0:e in t}};function j(t){B=t(B)}function de(t){return ce().includes(t)?function(...e){return t.apply(O(this),e),w(this.request)}:function(...e){return w(t.apply(O(this),e))}}function he(t){return typeof t=="function"?de(t):(t instanceof IDBTransaction&&ue(t),L(t,oe())?new Proxy(t,B):t)}function w(t){if(t instanceof IDBRequest)return le(t);if(M.has(t))return M.get(t);const e=he(t);return e!==t&&(M.set(t,e),I.set(e,t)),e}const O=t=>I.get(t);function me(t,e,{blocked:r,upgrade:n,blocking:s,terminated:o}={}){const i=indexedDB.open(t,e),c=w(i);return n&&i.addEventListener("upgradeneeded",l=>{n(w(i.result),l.oldVersion,l.newVersion,w(i.transaction),l)}),r&&i.addEventListener("blocked",l=>r(l.oldVersion,l.newVersion,l)),c.then(l=>{o&&l.addEventListener("close",()=>o()),s&&l.addEventListener("versionchange",u=>s(u.oldVersion,u.newVersion,u))}).catch(()=>{}),c}const fe=["get","getKey","getAll","getAllKeys","count"],ge=["put","add","delete","clear"],P=new Map;function _(t,e){if(!(t instanceof IDBDatabase&&!(e in t)&&typeof e=="string"))return;if(P.get(e))return P.get(e);const r=e.replace(/FromIndex$/,""),n=e!==r,s=ge.includes(r);if(!(r in(n?IDBIndex:IDBObjectStore).prototype)||!(s||fe.includes(r)))return;const o=async function(i,...c){const l=this.transaction(i,s?"readwrite":"readonly");let u=l.store;return n&&(u=u.index(c.shift())),(await Promise.all([u[r](...c),s&&l.done]))[0]};return P.set(e,o),o}j(t=>({...t,get:(e,r,n)=>_(e,r)||t.get(e,r,n),has:(e,r)=>!!_(e,r)||t.has(e,r)}));const ye=["continue","continuePrimaryKey","advance"],q={},V=new WeakMap,G=new WeakMap,we={get(t,e){if(!ye.includes(e))return t[e];let r=q[e];return r||(r=q[e]=function(...n){V.set(this,G.get(this)[e](...n))}),r}};async function*pe(...t){let e=this;if(e instanceof IDBCursor||(e=await e.openCursor(...t)),!e)return;e=e;const r=new Proxy(e,we);for(G.set(r,e),I.set(r,O(e));e;)yield r,e=await(V.get(r)||e.continue()),V.delete(r)}function z(t,e){return e===Symbol.asyncIterator&&L(t,[IDBIndex,IDBObjectStore,IDBCursor])||e==="iterate"&&L(t,[IDBIndex,IDBObjectStore])}j(t=>({...t,get(e,r,n){return z(e,r)?pe:t.get(e,r,n)},has(e,r){return z(e,r)||t.has(e,r)}}));const be="tthy",Se=1,p="pages";let x=null;async function S(){if(x)return x;try{return x=await me(be,Se,{upgrade(t){if(!t.objectStoreNames.contains(p)){const e=t.createObjectStore(p,{keyPath:"id"});e.createIndex("lastVisit","lastVisit",{unique:!1}),e.createIndex("status","status",{unique:!1}),e.createIndex("url","url",{unique:!1}),a.info("Database initialized with object store and indexes")}}}),x}catch(t){throw a.error("Failed to initialize database",t),t}}async function C(t){const e=await S();try{await e.put(p,t),a.debug(`Saved page: ${t.title} (${t.status})`)}catch(r){throw a.error("Failed to save page",r),r}}async function ke(t){const e=await S();try{return await e.get(p,t)}catch(r){throw a.error("Failed to get page",r),r}}async function Te(t,e=100){const r=await S();try{return await r.transaction(p,"readonly").store.index("status").getAll(t,e)}catch(n){throw a.error("Failed to list pages by status",n),n}}async function Ee(){const t=await S();try{await t.clear(p),a.info("All pages cleared from database")}catch(e){throw a.error("Failed to clear database",e),e}}async function ve(){const t=await S();try{const n=await t.transaction(p,"readonly").store.getAll(),s={totalPages:n.length,queuedPages:0,summarizedPages:0,failedPages:0,estimatedSize:0};let o=1/0,i=0;return n.forEach(c=>{c.status==="queued"?s.queuedPages++:c.status==="summarized"?s.summarizedPages++:c.status==="failed"&&s.failedPages++,c.lastVisit<o&&(o=c.lastVisit),c.lastVisit>i&&(i=c.lastVisit),s.estimatedSize+=JSON.stringify(c).length}),o!==1/0&&(s.oldestRecord=o),i!==0&&(s.newestRecord=i),s}catch(e){throw a.error("Failed to get stats",e),e}}const xe=["chrome:","chrome-extension:","about:","file:","data:"],Ce=500;async function Ie(t=48){const e=Date.now()-t*60*60*1e3;try{const r=await chrome.history.search({text:"",startTime:e,maxResults:Ce});return a.info(`Fetched ${r.length} history items from last ${t} hours`),r}catch(r){throw a.error("Failed to fetch history",r),r}}function Q(t){return t.filter(e=>!(!e.url||xe.some(n=>e.url.startsWith(n))||e.url.length<10))}async function Ae(t){const e=[],r=Q(t);for(const n of r)try{const s=n.url,o=n.lastVisitTime||Date.now(),i=await Re(s,o),c=await ke(i);if(c){const l={...c,lastVisit:Math.max(c.lastVisit,o),visitCount:c.visitCount+1};e.push(l)}else{const l={id:i,url:s,title:n.title||"Untitled",firstVisit:o,lastVisit:o,visitCount:n.visitCount||1,status:"queued"};e.push(l)}}catch(s){a.warn(`Failed to process history item: ${n.url}`,s)}for(const n of e)try{await C(n)}catch(s){a.error(`Failed to save record: ${n.url}`,s)}return a.info(`Merged ${e.length} records into database`),e}async function Re(t,e){const r=`${t}_${Math.floor(e/864e5)}`;return await ie(r)}async function U(t,e="all",r=200){try{const{start:n}=ne(e);a.info(`Searching history with ${t.length} expanded terms, time: ${e}`);const s=new Map;try{(await chrome.history.search({text:t.slice(0,5).join(" "),startTime:n,maxResults:r})).forEach(u=>{u.url&&s.set(u.url,u)})}catch(l){a.warn("Combined search failed",l)}if(s.size<50&&t.length>0)for(const l of t.slice(0,10)){if(l.length>2)try{(await chrome.history.search({text:l,startTime:n,maxResults:Math.min(50,r)})).forEach(h=>{h.url&&s.set(h.url,h)})}catch(u){a.debug(`Search for term "${l}" failed`,u)}if(s.size>=r)break}const o=Array.from(s.values()),i=Q(o);a.info(`Found ${i.length} history items from ${s.size} unique URLs`);const c=i.map(l=>{const u=l.title||"",h=l.url||"",f=u.toLowerCase(),m=h.toLowerCase();let d=0,g=[];t.forEach(E=>{const D=E.toLowerCase();D.length>2&&(f.includes(D)&&(d+=10,g.push(E)),m.includes(D)&&(d+=3,g.includes(E)||g.push(E)))});const R=(Date.now()-(l.lastVisitTime||0))/(24*60*60*1e3),X=Math.max(0,10-R);d+=X;const Z=Math.min(10,(l.visitCount||0)/5);d+=Z;const ee=g.length>0?`Found: ${g.slice(0,3).join(", ")}`:"Found in history";return{url:h,title:u||"Untitled",lastVisitTime:l.lastVisitTime||0,visitCount:l.visitCount||0,relevanceScore:d,matchReason:ee}}).sort((l,u)=>u.relevanceScore-l.relevanceScore).slice(0,r);return a.info(`Returning ${c.length} candidates for semantic ranking`),c}catch(n){return a.error("Failed to search history",n),[]}}const De=5,Me=1500,k=2e4;class Pe{constructor(e){b(this,"permits");b(this,"queue",[]);this.permits=e}async acquire(){if(this.permits>0){this.permits--;return}return new Promise(e=>{this.queue.push(e)})}release(){if(this.queue.length>0){const e=this.queue.shift();e==null||e()}else this.permits++}}const y=new Pe(3);async function T(t,e){const r=new Promise((n,s)=>setTimeout(()=>s(new Error("Operation timed out")),e));return Promise.race([t,r])}async function A(t,e=De){for(let r=0;r<e;r++)try{return await t()}catch(n){if(r===e-1)throw n;a.warn(`Retry ${r+1}/${e} after error:`,n),await new Promise(s=>setTimeout(s,Me*(r+1)))}throw new Error("Operation failed after retries")}async function K(){const t={languageModel:"no",summarizer:"no",rewriter:"no",translator:"no"},e=chrome.aiOriginTrial;try{if(e!=null&&e.languageModel){const r=await e.languageModel.capabilities();t.languageModel=r.available}}catch(r){a.debug("Language Model not available",r)}try{if(e!=null&&e.summarizer){const r=await e.summarizer.capabilities();t.summarizer=r.available}}catch(r){a.debug("Summarizer not available",r)}try{if(e!=null&&e.rewriter){const r=await e.rewriter.capabilities();t.rewriter=r.available}}catch(r){a.debug("Rewriter not available",r)}try{if(e!=null&&e.translator){const r=await e.translator.canDetect();t.translator=r}}catch(r){a.debug("Translator not available",r)}return a.info("AI Availability:",t),t}async function Le(t){await y.acquire();try{return await A(async()=>{const e=chrome.aiOriginTrial;if(!(e!=null&&e.languageModel))throw new Error("Language Model API not available");const r=await e.languageModel.create({systemPrompt:`You are a neutral summarizer. Summarize the following webpage content.
Keep product names and unique nouns. Target 500-1000 characters. Output plain text only, no markdown.`});try{const n=t.slice(0,4e3);return await T(r.prompt(n),k)}finally{r.destroy()}})}finally{y.release()}}async function $e(t){await y.acquire();try{return await A(async()=>{const e=chrome.aiOriginTrial;if(!(e!=null&&e.rewriter))throw new Error("Rewriter API not available");const r=await e.rewriter.create({sharedContext:"Create a one-sentence gist followed by 3-5 tags in brackets. Keep proper nouns."});try{return await T(r.rewrite(t,{context:"Example format: 'ContentCal helps teams plan social content. [SaaS][content-planning][calendar]'"}),k)}finally{r.destroy()}})}finally{y.release()}}async function Be(t){var e;try{const r=chrome.aiOriginTrial;if(!(r!=null&&r.translator))return"en";const n=await r.translator.createDetector();return((e=(await T(n.detect(t.slice(0,1e3)),k))[0])==null?void 0:e.detectedLanguage)||"en"}catch(r){return a.warn("Language detection failed, defaulting to en",r),"en"}}async function Oe(t){await y.acquire();try{return await A(async()=>{const e=chrome.aiOriginTrial;if(!(e!=null&&e.languageModel))throw new Error("Language Model API not available");const r=await e.languageModel.create({systemPrompt:`You are a semantic search query expander for web browsing history. Your job is to think deeply about what the user wants and expand their query into ALL relevant terms, brands, products, and concepts.

THINK STEP BY STEP:
1. What is the user really looking for?
2. What are the popular brands/products in this category?
3. What are related terms and synonyms?
4. What websites or domains would contain this content?

EXAMPLES:

Query: "social media management platform"
Think: User wants tools to manage social media posts
Brands: Publer, Buffer, Hootsuite, Later, Sprout Social, Agorapulse, CoSchedule
Terms: scheduling, content calendar, post management, social networks, automation
Related: Twitter, Facebook, Instagram, LinkedIn, content marketing
Result: ["social media", "management", "platform", "Publer", "Buffer", "Hootsuite", "Later", "Sprout Social", "Agorapulse", "CoSchedule", "scheduling", "content calendar", "posts", "Twitter", "Facebook", "Instagram", "LinkedIn", "automation", "social networks"]

Query: "code repository hosting"
Think: User wants git hosting services
Brands: GitHub, GitLab, Bitbucket, Gitea
Terms: git, repository, source control, version control, code hosting
Related: repositories, commits, pull requests, merge
Result: ["code", "repository", "hosting", "GitHub", "GitLab", "Bitbucket", "Gitea", "git", "version control", "source control", "commits", "pull requests", "repositories", "merge"]

Query: "video streaming site"
Think: User wants video platforms
Brands: YouTube, Vimeo, Twitch, Dailymotion
Terms: video, streaming, watch, channel
Related: videos, live streaming, content creator
Result: ["video", "streaming", "site", "YouTube", "Vimeo", "Twitch", "Dailymotion", "watch", "videos", "channel", "live", "content creator"]

Be COMPREHENSIVE. Include 15-25 terms for best coverage.

Time references:
- "yesterday" = yesterday
- "today" or "few hours ago" = today
- "last week" or "this week" = week
- "last month" or "this month" = month
- No time reference = month (default to last 30 days for best results)

Return ONLY valid JSON with no markdown or explanations.
Format: {
  "timeWindow": "today|yesterday|week|two_weeks|month|all",
  "expandedTerms": ["term1", "brand1", "brand2", "concept1", ...],
  "primaryKeywords": ["main", "keywords"],
  "intent": "brief description of what user wants"
}`});try{const n=`User query: "${t}"

Expand this query into related terms, brands, and concepts. Extract time window. Return only JSON.`,o=(await T(r.prompt(n),k)).replace(/```json\n?/g,"").replace(/```\n?/g,"").trim(),i=JSON.parse(o);return{originalQuery:t,expandedTerms:i.expandedTerms||[],primaryKeywords:i.primaryKeywords||[],timeWindow:i.timeWindow||"month",intent:i.intent}}finally{r.destroy()}})}catch(e){a.warn("Query expansion failed, using fallback",e);const r=t.toLowerCase();let n="month";r.includes("yesterday")?n="yesterday":r.includes("today")||r.includes("hours ago")||r.includes("hour ago")?n="today":r.includes("last week")||r.includes("this week")?n="week":r.includes("last month")||r.includes("this month")?n="month":(r.includes("all time")||r.includes("ever"))&&(n="all");const s=["yesterday","today","last","week","month","looked","visited","viewed","website","site","find","show","search","for","the","and","or"],o=t.split(" ").filter(i=>i.length>2&&!s.includes(i.toLowerCase()));return{originalQuery:t,expandedTerms:o,primaryKeywords:o,timeWindow:n,intent:t}}finally{y.release()}}async function Ve(t,e,r){return r.length===0?[]:r.length>100?(a.info(`Large candidate set (${r.length}), ranking in batches...`),await Ne(t,e,r)):await Y(t,e,r,0)}async function Ne(t,e,r){const s=[];for(let o=0;o<r.length;o+=100){const i=r.slice(o,o+100);a.debug(`Ranking batch ${Math.floor(o/100)+1}/${Math.ceil(r.length/100)}`);const c=await Y(t,e,i,o);s.push(...c)}return s.sort((o,i)=>o.rank-i.rank)}async function Y(t,e,r,n){await y.acquire();try{return await A(async()=>{const s=chrome.aiOriginTrial;if(!(s!=null&&s.languageModel))throw new Error("Language Model API not available");const o=await s.languageModel.create({systemPrompt:`You are a semantic search ranker. Rank pages by semantic relevance to the user's intent, not just keyword matches.

Consider:
- Brand names and products (e.g., "Publer" is relevant to "social media platform")
- Product categories (e.g., "YouTube" is relevant to "video streaming")
- Website domains help identify purpose:
  * github.com, gitlab.com → code hosting
  * youtube.com, vimeo.com → video streaming
  * amazon.com, ebay.com → online shopping
  * twitter.com, facebook.com → social networks
  * jira.atlassian.com, trello.com → project management
- Related concepts (e.g., "scheduling" is relevant to "content management")
- User intent behind the query

STRICT CONFIDENCE SCORING:
- 0.9-1.0: Perfect match - page is exactly what user wants
- 0.7-0.9: Strong match - highly relevant to query
- 0.5-0.7: Moderate match - somewhat relevant
- Below 0.5: Weak or irrelevant - DO NOT INCLUDE

Example: Query "social media management platform"
- "Publer - Social Media Scheduling | publer.io" → confidence: 0.95 (perfect match)
- "Buffer: Social Media Dashboard | buffer.com" → confidence: 0.9 (strong match)
- "Twitter Home Timeline | twitter.com" → confidence: 0.4 (not a management tool, exclude)

Be strict. Only include results you're confident are relevant.

Return ONLY a JSON array with no markdown or explanations.
Format: [{"index": 0, "rank": 1, "matchReason": "explain semantic relevance clearly", "confidence": 0.95}]
Index is the page's position in the input list. Rank is 1 for best match.`});try{const i=r.map((m,d)=>{try{const g=new URL(m.url).hostname,R=m.visitCount>1?` [${m.visitCount} visits]`:"";return`${d}. ${m.title} | ${g}${R}`}catch{return`${d}. ${m.title}`}}).join(`
`),c=e.length>0?`

Search context (related terms found): ${e.slice(0,15).join(", ")}`:"",l=`User is looking for: "${t}"${c}

History pages to rank:
${i}

Rank these pages by semantic relevance. Use domain names to understand site types. Be strict with confidence scores (minimum 0.5). Return only JSON array.`,h=(await T(o.prompt(l),k)).replace(/```json\n?/g,"").replace(/```\n?/g,"").trim();return JSON.parse(h).filter(m=>m.confidence>=.5).map(m=>{const d=r[m.index];return{id:`history-${d.url}`,url:d.url,title:d.title,firstVisit:d.lastVisitTime,lastVisit:d.lastVisitTime,visitCount:d.visitCount,status:"summarized",rank:n/100*1e3+m.rank,matchReason:m.matchReason||"Semantically relevant"}}).sort((m,d)=>m.rank-d.rank)}finally{o.destroy()}})}catch(s){a.warn("Semantic ranking failed for batch, using keyword-based fallback",s);const o=t.toLowerCase(),i=e.map(c=>c.toLowerCase());return r.map(c=>{const l=c.title.toLowerCase(),u=c.url.toLowerCase();let h=0;return o.split(" ").forEach(f=>{f.length>2&&(l.includes(f)&&(h+=10),u.includes(f)&&(h+=5))}),i.forEach(f=>{l.includes(f)&&(h+=8),u.includes(f)&&(h+=3)}),h+=c.relevanceScore||0,{id:`history-${c.url}`,url:c.url,title:c.title,firstVisit:c.lastVisitTime,lastVisit:c.lastVisitTime,visitCount:c.visitCount,status:"summarized",rank:0,matchReason:h>15?"Strong keyword match":"Related match",score:h}}).filter(c=>c.score>0).sort((c,l)=>l.score-c.score).map((c,l)=>({...c,rank:l+1})).slice(0,20)}finally{y.release()}}const Fe=3,_e=10;class qe{constructor(){b(this,"queue",[]);b(this,"processing",0);b(this,"callbacks",[])}add(e){this.queue.push(e)}async getNext(){for(;this.queue.length===0&&this.processing>0;)await new Promise(e=>{this.callbacks.push(e)});return this.queue.shift()||null}startProcessing(){this.processing++}finishProcessing(){this.processing--;const e=this.callbacks.shift();e&&e()}get hasWork(){return this.queue.length>0||this.processing>0}}async function ze(){a.info("Starting scan and index operation");try{const t=await Ie(48);await Ae(t);const e=await Te("queued",_e);if(a.info(`Found ${e.length} queued pages to process`),e.length===0){a.info("No pages to process");return}const r=new qe;e.forEach(s=>r.add(s));const n=Array.from({length:Fe},()=>Ue(r));await Promise.all(n),a.info("Scan and index operation completed")}catch(t){throw a.error("Scan and index operation failed",t),t}}async function Ue(t){for(;t.hasWork;){const e=await t.getNext();if(!e)break;t.startProcessing();try{const r=await He(e);await C(r),a.info(`Successfully processed: ${r.title}`)}catch(r){a.error(`Failed to process page: ${e.url}`,r),e.status="failed",await C(e)}finally{t.finishProcessing()}}}async function He(t){try{const{title:e,text:r}=await We(t.url);if(!r||r.length<100)throw new Error("Insufficient content extracted");a.debug(`Summarizing: ${e}`);const n=await Le(r);a.debug(`Creating memory card: ${e}`);const s=await $e(n),o=await Be(r),i=ae(s);return{...t,title:e||t.title,summary:n,memoryCard:s,lang:o,tags:i,status:"summarized"}}catch(e){throw a.error(`Processing failed for ${t.url}`,e),e}}async function We(t){try{const e=await chrome.tabs.query({url:t});if(e.length>0&&e[0].id)try{const i=await chrome.tabs.sendMessage(e[0].id,{type:"EXTRACT_READABLE"});if(i!=null&&i.success&&i.data)return{title:i.data.title,text:i.data.text}}catch(i){a.debug("Content script extraction failed, trying fetch",i)}const r=await fetch(t,{method:"GET",headers:{"User-Agent":"Chrome-Extension"}});if(!r.ok)throw new Error(`HTTP ${r.status}`);const n=await r.text(),s=je(n).slice(0,2e5);return{title:Ge(n),text:s}}catch(e){throw a.warn(`Failed to extract content from ${t}`,e),e}}function je(t){return t.replace(/<script\b[^<]*(?:(?!<\/script>)<[^<]*)*<\/script>/gi,"").replace(/<style\b[^<]*(?:(?!<\/style>)<[^<]*)*<\/style>/gi,"").replace(/<[^>]+>/g," ").replace(/\s+/g," ").trim()}function Ge(t){const e=t.match(/<title[^>]*>([^<]+)<\/title>/i);return e?e[1].trim():"Untitled"}const H="scanHistory",W=15;function Qe(){a.info("Initializing scheduler"),chrome.alarms.create(H,{periodInMinutes:W,delayInMinutes:1}),chrome.alarms.onAlarm.addListener(t=>{t.name===H&&J()}),a.info(`Scheduler initialized with ${W} minute interval`)}async function J(){var n;if(!(((n=(await chrome.storage.sync.get("settings")).settings)==null?void 0:n.indexingEnabled)??!0))throw new Error("Indexing is disabled. Please enable it in settings.");if((await K()).languageModel!=="readily")throw new Error("Chrome AI is not ready. Enable flags at chrome://flags and wait for model download.");a.info("Running scan with AI ready"),await ze(),await chrome.storage.sync.set({lastScanTime:Date.now()}),a.info("Scan completed successfully")}chrome.runtime.onInstalled.addListener(async t=>{a.info("Extension installed/updated",t.reason);try{Qe(),t.reason==="install"&&await Ke();const e=await K();a.info("AI APIs availability:",e)}catch(e){a.error("Initialization failed",e)}});async function Ke(){a.info("First install detected");const t={indexingEnabled:!1,ignoredDomains:[],preferredLanguage:"en",maxPagesPerDay:100};await chrome.storage.sync.set({settings:t,firstRun:!0}),a.info("Default settings saved")}chrome.runtime.onMessage.addListener((t,e,r)=>{switch(a.debug("Received message:",t.type),t.type){case"SEARCH_QUERY":return Ye(t).then(n=>{r({type:"SEARCH_RESPONSE",results:n})}).catch(n=>{a.error("Search query failed",n),r({type:"SEARCH_RESPONSE",results:[],error:n.message})}),!0;case"GET_STATS":return Je().then(n=>{r({type:"STATS_RESPONSE",stats:n})}).catch(n=>{a.error("Get stats failed",n),r({type:"STATS_RESPONSE",stats:null,error:n.message})}),!0;case"ERASE_ALL_DATA":return Xe().then(()=>{r({success:!0})}).catch(n=>{a.error("Erase data failed",n),r({success:!1,error:n.message})}),!0;case"SEED_TEST_DATA":return Ze().then(()=>{r({success:!0})}).catch(n=>{a.error("Seed test data failed",n),r({success:!1,error:n.message})}),!0;case"TRIGGER_SCAN":return et().then(()=>{r({success:!0})}).catch(n=>{a.error("Trigger scan failed",n),r({success:!1,error:n.message})}),!0;case"GET_SETTINGS":return tt().then(n=>{r({settings:n})}).catch(n=>{a.error("Get settings failed",n),r({settings:null,error:n.message})}),!0;case"UPDATE_SETTINGS":return rt(t).then(()=>{r({success:!0})}).catch(n=>{a.error("Update settings failed",n),r({success:!1,error:n.message})}),!0;default:return a.warn("Unknown message type:",t.type),r({error:"Unknown message type"}),!1}});async function Ye(t){a.info("🔍 Processing semantic search query:",t.query);try{a.debug("Step 1: Expanding query with AI...");const e=await Oe(t.query);a.info("✨ Query expanded:",{intent:e.intent,terms:e.expandedTerms.length,timeWindow:e.timeWindow}),a.debug("Step 2: Searching Chrome history...");const r=await U(e.expandedTerms,e.timeWindow,200);if(a.info(`📚 Found ${r.length} candidate history items`),r.length===0)return a.info("No history items found"),[];a.debug(`Step 3: Ranking ALL ${r.length} candidates semantically with AI...`);const n=await Ve(t.query,e.expandedTerms,r);return a.info(`✅ Returning ${n.length} semantically ranked results (confidence ≥ 0.5)`),n.slice(0,20)}catch(e){a.error("❌ AI semantic search failed:",e),a.warn("⚠️ Falling back to keyword search (AI unavailable)");try{const r=t.query.split(" ").filter(s=>s.length>2);return(await U(r,"month",50)).slice(0,20).map((s,o)=>({id:`history-${s.url}`,url:s.url,title:s.title,firstVisit:s.lastVisitTime,lastVisit:s.lastVisitTime,visitCount:s.visitCount,status:"summarized",rank:o+1,matchReason:`⚠️ Keyword match (AI unavailable): ${s.matchReason}`}))}catch(r){return a.error("Fallback search also failed:",r),[]}}}async function Je(t){const e=await ve(),r=await chrome.storage.sync.get("lastScanTime");return e.lastScanTime=r.lastScanTime,e}async function Xe(t){a.warn("Erasing all data"),await Ee(),await chrome.storage.sync.clear(),a.info("All data erased")}async function Ze(t){a.info("Seeding test data");const e=[{id:"test1",url:"https://example.com/contentcal",title:"ContentCal - Social Media Planning Tool",firstVisit:Date.now()-7*24*60*60*1e3,lastVisit:Date.now()-7*24*60*60*1e3,visitCount:2,lang:"en",summary:"ContentCal is a comprehensive social media planning and scheduling tool designed for marketing teams. It offers calendar views, content approval workflows, and analytics.",memoryCard:"ContentCal helps teams plan and schedule social media content with calendar views and approval workflows. [SaaS][social-media][content-planning][marketing]",tags:["SaaS","social-media","content-planning","marketing"],status:"summarized"},{id:"test2",url:"https://example.com/ai-pricing",title:"AI Agent Pricing Models - Complete Guide",firstVisit:Date.now()-30*24*60*60*1e3,lastVisit:Date.now()-30*24*60*60*1e3,visitCount:1,lang:"en",summary:"This article explores various pricing models for AI agents, including token-based, subscription, and usage-based pricing. Covers OpenAI, Anthropic, and other providers.",memoryCard:"Guide to AI agent pricing models covering token-based, subscription, and usage pricing from major providers. [AI][pricing][business-model][SaaS]",tags:["AI","pricing","business-model","SaaS"],status:"summarized"},{id:"test3",url:"https://example.com/hubspot-shortcuts",title:"HubSpot Keyboard Shortcuts FAQ",firstVisit:Date.now()-1*24*60*60*1e3,lastVisit:Date.now()-1*24*60*60*1e3,visitCount:3,lang:"en",summary:"Frequently asked questions about HubSpot keyboard shortcuts and productivity tips. Includes shortcuts for contacts, deals, and email management.",memoryCard:"HubSpot FAQ covering keyboard shortcuts for contacts, deals, and email productivity. [CRM][HubSpot][shortcuts][productivity]",tags:["CRM","HubSpot","shortcuts","productivity"],status:"summarized"}];for(const r of e)await C(r);a.info(`Seeded ${e.length} test pages`)}async function et(t){a.info("Manually triggering scan"),await J()}async function tt(t){return(await chrome.storage.sync.get("settings")).settings||{indexingEnabled:!1,ignoredDomains:[],preferredLanguage:"en",maxPagesPerDay:100}}async function rt(t){const r={...(await chrome.storage.sync.get("settings")).settings,...t.settings};await chrome.storage.sync.set({settings:r}),a.info("Settings updated",r)}a.info("Background service worker loaded");
